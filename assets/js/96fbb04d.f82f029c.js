"use strict";(self.webpackChunksinnammanyo_cn=self.webpackChunksinnammanyo_cn||[]).push([[7554],{77362:(t,n,e)=>{e.r(n),e.d(n,{assets:()=>i,contentTitle:()=>l,default:()=>p,frontMatter:()=>o,metadata:()=>c,toc:()=>r});var s=e(87462),a=(e(67294),e(3905));e(83989);const o={id:"opencv-dnn-ultralytics",title:"",sidebar_label:"DNN YOLO-v8-ONNX"},l=void 0,c={unversionedId:"cv/opencv/dnn/opencv-dnn-ultralytics",id:"cv/opencv/dnn/opencv-dnn-ultralytics",title:"",description:"\u4f7f\u7528 CV::DNN \u6a21\u5757\u8bfb\u53d6 ultralytics/YOLO-v8 ONNX \u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b",source:"@site/docs/stack/cv/opencv/dnn/dnn-ultralytics.md",sourceDirName:"cv/opencv/dnn",slug:"/cv/opencv/dnn/opencv-dnn-ultralytics",permalink:"/stack/cv/opencv/dnn/opencv-dnn-ultralytics",draft:!1,editUrl:"https://github.com/rcxxx/sinnammanyo.cn/tree/master/docs/stack/cv/opencv/dnn/dnn-ultralytics.md",tags:[],version:"current",frontMatter:{id:"opencv-dnn-ultralytics",title:"",sidebar_label:"DNN YOLO-v8-ONNX"},sidebar:"\ud83d\udc40CV & Robot",previous:{title:"DNN YOLO-v5-ONNX",permalink:"/stack/cv/opencv/dnn/opencv-dnn-yolov5-6-0"},next:{title:"\u8f66\u9053\u7ebf\u68c0\u6d4b",permalink:"/stack/cv/opencv/demo/\u8f66\u9053\u7ebf\u68c0\u6d4b/opencv-lane-detect"}},i={},r=[{value:"\u4f7f\u7528 CV::DNN \u6a21\u5757\u8bfb\u53d6 ultralytics/YOLO-v8 ONNX \u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b",id:"\u4f7f\u7528-cvdnn-\u6a21\u5757\u8bfb\u53d6-ultralyticsyolo-v8-onnx-\u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b",level:2},{value:"\u8fd0\u884c\u73af\u5883",id:"\u8fd0\u884c\u73af\u5883",level:3},{value:"\u83b7\u53d6 ONNX \u6a21\u578b",id:"\u83b7\u53d6-onnx-\u6a21\u578b",level:2},{value:"clone \u6e90\u7801",id:"clone-\u6e90\u7801",level:3},{value:"\u5b89\u88c5",id:"\u5b89\u88c5",level:3},{value:"\u4e0b\u8f7d\u6a21\u578b",id:"\u4e0b\u8f7d\u6a21\u578b",level:3},{value:"export \u5bfc\u51fa onnx \u6a21\u578b",id:"export-\u5bfc\u51fa-onnx-\u6a21\u578b",level:3},{value:"OpenCV-DNN \u5bfc\u5165 ONNX \u6a21\u578b",id:"opencv-dnn-\u5bfc\u5165-onnx-\u6a21\u578b",level:2},{value:"Class YoloNet()",id:"class-yolonet",level:3},{value:"\u53c2\u8003",id:"\u53c2\u8003",level:2}],d={toc:r};function p(t){let{components:n,...e}=t;return(0,a.kt)("wrapper",(0,s.Z)({},d,e,{components:n,mdxType:"MDXLayout"}),(0,a.kt)("h2",{id:"\u4f7f\u7528-cvdnn-\u6a21\u5757\u8bfb\u53d6-ultralyticsyolo-v8-onnx-\u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b"},"\u4f7f\u7528 CV::DNN \u6a21\u5757\u8bfb\u53d6 ultralytics/YOLO-v8 ONNX \u6a21\u578b\u8fdb\u884c\u5b9e\u65f6\u76ee\u6807\u68c0\u6d4b"),(0,a.kt)("h3",{id:"\u8fd0\u884c\u73af\u5883"},"\u8fd0\u884c\u73af\u5883"),(0,a.kt)("table",null,(0,a.kt)("thead",{parentName:"table"},(0,a.kt)("tr",{parentName:"thead"},(0,a.kt)("th",{parentName:"tr",align:null},"name"),(0,a.kt)("th",{parentName:"tr",align:"center"},"version"))),(0,a.kt)("tbody",{parentName:"table"},(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"System"),(0,a.kt)("td",{parentName:"tr",align:"center"},(0,a.kt)("strong",{parentName:"td"},(0,a.kt)("a",{parentName:"strong",href:"https://releases.ubuntu.com/20.04/"},"Ubuntu 20.04")))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"CMake"),(0,a.kt)("td",{parentName:"tr",align:"center"},(0,a.kt)("strong",{parentName:"td"},(0,a.kt)("a",{parentName:"strong",href:"https://cmake.org/"},"3.24"))," \u2265")),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"OpenCV"),(0,a.kt)("td",{parentName:"tr",align:"center"},(0,a.kt)("strong",{parentName:"td"},(0,a.kt)("a",{parentName:"strong",href:"https://github.com/opencv/opencv/releases/tag/4.6.0"},"4.6.0")))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"Python"),(0,a.kt)("td",{parentName:"tr",align:"center"},(0,a.kt)("strong",{parentName:"td"},(0,a.kt)("a",{parentName:"strong",href:"https://www.python.org/downloads/release/python-380/"},"3.8.0")))),(0,a.kt)("tr",{parentName:"tbody"},(0,a.kt)("td",{parentName:"tr",align:null},"YOLOv8"),(0,a.kt)("td",{parentName:"tr",align:"center"},(0,a.kt)("strong",{parentName:"td"},(0,a.kt)("a",{parentName:"strong",href:"https://github.com/ultralytics/ultralytics"},"ultralytics")))))),(0,a.kt)("h2",{id:"\u83b7\u53d6-onnx-\u6a21\u578b"},"\u83b7\u53d6 ONNX \u6a21\u578b"),(0,a.kt)("h3",{id:"clone-\u6e90\u7801"},"clone \u6e90\u7801"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"git clone https://github.com/ultralytics/ultralytics.git\n")),(0,a.kt)("h3",{id:"\u5b89\u88c5"},"\u5b89\u88c5"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"cd ultralytics/\npip install -r requirements.txt\npip install ultralytics\n")),(0,a.kt)("h3",{id:"\u4e0b\u8f7d\u6a21\u578b"},"\u4e0b\u8f7d\u6a21\u578b"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},'yolo predict model=yolov8n.pt source="https://ultralytics.com/images/bus.jpg"\n')),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("inlineCode",{parentName:"li"},"model={}")," \u586b\u5165\u6240\u9700\u8981\u7684\u6a21\u578b\uff0c\u5982\u679c\u672c\u5730\u6ca1\u6709\u5219\u4f1a\u4ece\u4ed3\u5e93\u4e0b\u8f7d")),(0,a.kt)("h3",{id:"export-\u5bfc\u51fa-onnx-\u6a21\u578b"},"export \u5bfc\u51fa onnx \u6a21\u578b"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u5b89\u88c5 onnx")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"pip install onnx\npip install onnxsim\n")),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},"\u5bfc\u51fa\u6a21\u578b")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre"},"yolo export \\\nmodel=yolov8s.pt \\\nimgsz=[480,640] \\\nformat=onnx \\\nopset=12\n")),(0,a.kt)("h2",{id:"opencv-dnn-\u5bfc\u5165-onnx-\u6a21\u578b"},"OpenCV-DNN \u5bfc\u5165 ONNX \u6a21\u578b"),(0,a.kt)("h3",{id:"class-yolonet"},"Class YoloNet()"),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cpp",metastring:'title="yolov8_onnx.hpp"',title:'"yolov8_onnx.hpp"'},"#include <fstream>\n#include <vector>\n#include <string>\n#include <random>\n\n#include <opencv2/imgproc.hpp>\n#include <opencv2/opencv.hpp>\n#include <opencv2/dnn.hpp>\n\nnamespace yolov8_onnx {\n    struct Detection\n    {\n        int class_id{0};\n        std::string className{};\n        float confidence{0.0};\n        cv::Scalar color{};\n        cv::Rect box{};\n    };\n\n    class Net\n    {\n    public:\n        explicit Net(const std::string &onnx_model_path, const std::string &classes_txt_file_path,\n                     const cv::Size &model_input_shape = {640, 640}, const bool &is_cuda = false);\n\n        ~Net()= default;\n\n        std::vector<yolov8_onnx::Detection> detect(cv::Mat &src,\n                                              float _score_threshold = 0.2,\n                                              float _NMS_threshold = 0.4,\n                                              float _confidence_threshold = 0.4);\n        inline std::vector<std::string> classList(){\n            return this->class_list_;\n        }\n\n    private:\n        cv::dnn::Net net;\n        std::vector<std::string> class_list_;\n\n        cv::Size2f model_shape_{};\n\n        static cv::Mat format_img(const cv::Mat &_src);\n    };\n};\n")),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cpp",metastring:'title="yolov8_onnx.cpp"',title:'"yolov8_onnx.cpp"'},'#include "yolov_8_onnx.hpp"\n\nnamespace yolov8_onnx {\n\n    Net::Net(const std::string &onnx_model_path, const std::string &classes_txt_file_path,\n             const cv::Size &model_input_shape, const bool &is_cuda) {\n        // load models\n        this->net = cv::dnn::readNetFromONNX(onnx_model_path);\n        if (is_cuda)\n        {\n            std::cout << "\\nRunning on CUDA" << std::endl;\n            net.setPreferableBackend(cv::dnn::DNN_BACKEND_CUDA);\n            net.setPreferableTarget(cv::dnn::DNN_TARGET_CUDA);\n        }\n        else\n        {\n            std::cout << "\\nRunning on CPU" << std::endl;\n            net.setPreferableBackend(cv::dnn::DNN_BACKEND_OPENCV);\n            net.setPreferableTarget(cv::dnn::DNN_TARGET_CPU);\n        }\n\n        // load class_list\n        std::ifstream ifs(classes_txt_file_path);\n        if (ifs.is_open())\n        {\n            std::string line;\n            while (getline(ifs, line))\n            {\n                this->class_list_.push_back(line);\n            }\n        }\n\n        this->model_shape_ = model_input_shape;\n    }\n\n    std::vector<yolov8_onnx::Detection>\n    Net::detect(cv::Mat &src,\n                float _score_threshold,\n                float _NMS_threshold,\n                float _confidence_threshold) {\n        // format image\n        cv::Mat input = format_img(src);\n\n        cv::Mat blob;\n        cv::dnn::blobFromImage(input, blob, 1.0/255.0, this->model_shape_, cv::Scalar(), true, false);\n        net.setInput(blob);\n\n        std::vector<cv::Mat> outputs;\n        net.forward(outputs, net.getUnconnectedOutLayersNames());\n\n        // yolo_v8 has an output of shape (batchSize, 84,  8400) (Num classes + box[x,y,w,h])\n        int rows = outputs[0].size[2];\n        int dimensions = outputs[0].size[1];\n\n        outputs[0] = outputs[0].reshape(1, dimensions);\n        cv::transpose(outputs[0], outputs[0]);\n\n        auto *data = (float *)outputs[0].data;\n\n        float x_factor = static_cast<float >(input.cols) / this->model_shape_.width;\n        float y_factor = static_cast<float >(input.rows) / this->model_shape_.height;\n\n        std::vector<int> class_ids;\n        std::vector<float> confidences;\n        std::vector<cv::Rect> boxes;\n\n        for (int i = 0; i < rows; ++i)\n        {\n            float *classes_scores = data+4;\n\n            cv::Mat scores(1, static_cast<int>(this->class_list_.size()), CV_32FC1, classes_scores);\n            cv::Point class_id;\n            double max_class_score;\n\n            minMaxLoc(scores, 0, &max_class_score, 0, &class_id);\n            if (max_class_score > _score_threshold){\n                confidences.push_back(max_class_score);\n                class_ids.push_back(class_id.x);\n\n                float x = data[0];\n                float y = data[1];\n                float w = data[2];\n                float h = data[3];\n\n                int left = static_cast<int>((x - 0.5 * w) * x_factor);\n                int top = static_cast<int>(( y - 0.5 * h) * y_factor);\n\n                int width = static_cast<int>(w * x_factor);\n                int height = static_cast<int>(h * y_factor);\n\n                boxes.emplace_back(left, top, width, height);\n            }\n            data += dimensions;\n        }\n\n        std::vector<int> nms_result;\n        cv::dnn::NMSBoxes(boxes, confidences, _score_threshold, _NMS_threshold, nms_result);\n\n        std::vector<yolov8_onnx::Detection> detections{};\n        for(auto i = 0; i< nms_result.size(); ++i){\n            int idx = nms_result[i];\n\n            yolov8_onnx::Detection result;\n            result.class_id = class_ids[idx];\n            result.confidence = confidences[idx];\n\n            std::random_device rd;\n            std::mt19937 gen(rd());\n            std::uniform_int_distribution<int> dis(100, 255);\n            result.color = cv::Scalar(dis(gen),\n                                      dis(gen),\n                                      dis(gen));\n\n            result.className = class_list_[result.class_id];\n            result.box = boxes[idx];\n\n            detections.push_back(result);\n        }\n\n        return detections;\n    }\n\n    cv::Mat Net::format_img(const cv::Mat &_src) {\n        int format_size = MAX(_src.cols, _src.rows);\n\n        cv::Mat dst = cv::Mat::zeros(cv::Size(format_size, format_size), CV_8UC3);\n        _src.copyTo(dst(cv::Rect(0, 0, _src.cols, _src.rows)));\n\n        return dst;\n    }\n};\n')),(0,a.kt)("blockquote",null,(0,a.kt)("ul",{parentName:"blockquote"},(0,a.kt)("li",{parentName:"ul"},"v8 \u4e0e v5 \u5728 output \u7ed3\u6784\u4e0a\u6709\u533a\u522b\n// yolov5 has an output of shape (batchSize, 25200, 85) (Num classes + box","[x,y,w,h]"," + confidence","[c]",")\n// yolov8 has an output of shape (batchSize, 84,  8400) (Num classes + box","[x,y,w,h]",")"))),(0,a.kt)("pre",null,(0,a.kt)("code",{parentName:"pre",className:"language-cpp",metastring:'title="main.cpp"',title:'"main.cpp"'},'#include <iostream>\n\n#include <opencv2/opencv.hpp>\n\n#include "yolov8/yolov_8_onnx.hpp"\n\nint main() {\n    std::string model_path = "../models/yolov8s.onnx";\n    std::string classes_path = "../models/classes.txt";\n    std::string img_path = "../img/bus.jpg";\n\n    yolov8_onnx::Net yolo(model_path, classes_path);\n\n    cv::Mat src_img = cv::imread(img_path);\n\n    // YOLO detect\n    std::vector<yolov8_onnx::Detection> results = yolo.detect(src_img);\n    for (const auto &idx : results) {\n//        if (idx.class_id == 15 || idx.class_id == 16) {\n            auto bbox = idx.box;\n            auto classId = idx.class_id;\n            cv::rectangle(src_img, bbox, idx.color, 2);\n            cv::rectangle(src_img, cv::Point(bbox.x, bbox.y + 10), cv::Point(bbox.x + bbox.width, bbox.y), idx.color, cv::FILLED);\n            cv::putText(src_img, yolo.classList()[classId], cv::Point(bbox.x, bbox.y + 5), cv::FONT_HERSHEY_SIMPLEX, 0.5, cv::Scalar(0, 0, 0));\n//        }\n    }\n\n    cv::imshow("src_img", src_img);\n    cv::waitKey(0);\n\n    return 0;\n}\n')),(0,a.kt)("p",null,"\u8f93\u51fa\u7ed3\u679c\u5982\u4e0b"),(0,a.kt)("h2",{id:"\u53c2\u8003"},"\u53c2\u8003"),(0,a.kt)("ul",null,(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("a",{parentName:"strong",href:"https://github.com/ultralytics/ultralytics"},"ultralytics/ultralytics"))),(0,a.kt)("li",{parentName:"ul"},(0,a.kt)("strong",{parentName:"li"},(0,a.kt)("a",{parentName:"strong",href:"https://github.com/ultralytics/ultralytics/tree/main/examples/YOLOv8-CPP-Inference"},"ultralytics/examples/YOLOv8-CPP-Inference")))))}p.isMDXComponent=!0}}]);